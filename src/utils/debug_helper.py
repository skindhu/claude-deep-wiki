"""
Debug è¾…åŠ©å·¥å…·

ç”¨äºä¿å­˜åˆ†æè¿‡ç¨‹ä¸­çš„ä¸­é—´ç»“æœï¼Œæ–¹ä¾¿è°ƒè¯•å’Œé—®é¢˜æ’æŸ¥
"""

import json
import datetime
from pathlib import Path
from typing import Any, Optional

from config import DEBUG_DIR, ensure_debug_dir


class DebugHelper:
    """Debug è¾…åŠ©ç±»"""

    def __init__(self, enabled: bool = False, verbose: bool = False):
        """
        åˆå§‹åŒ– Debug Helper

        Args:
            enabled: æ˜¯å¦å¯ç”¨ debug æ¨¡å¼
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        """
        self.enabled = enabled
        self.verbose = verbose
        self.debug_dir = DEBUG_DIR

        if self.enabled:
            ensure_debug_dir()
            self._log(f"ğŸ› è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼Œä¸­é—´ç»“æœå°†ä¿å­˜åˆ°: {self.debug_dir}")

    def save_stage_data(self, stage: str, raw_response: str, extracted_data: Any):
        """
        ä¿å­˜åˆ†æé˜¶æ®µçš„æ•°æ®

        Args:
            stage: é˜¶æ®µåç§°ï¼ˆå¦‚ "01_overview", "02_module_01"ï¼‰
            raw_response: åŸå§‹å“åº”æ–‡æœ¬
            extracted_data: æå–çš„ç»“æ„åŒ–æ•°æ®
        """
        if not self.enabled:
            return

        # æ¸…ç† stage åç§°ï¼Œæ›¿æ¢ä¸å®‰å…¨çš„æ–‡ä»¶åå­—ç¬¦
        import re
        safe_stage = re.sub(r'[^\w\-]', '_', stage)

        timestamp = self._get_timestamp()

        # ä¿å­˜åŸå§‹å“åº”
        raw_file = self.debug_dir / f"{timestamp}_{safe_stage}_raw.txt"
        with open(raw_file, 'w', encoding='utf-8') as f:
            f.write(raw_response)

        # ä¿å­˜æå–çš„æ•°æ®
        extracted_file = self.debug_dir / f"{timestamp}_{safe_stage}_extracted.json"
        with open(extracted_file, 'w', encoding='utf-8') as f:
            json.dump(extracted_data, f, ensure_ascii=False, indent=2)

        self._log(f"  ğŸ› è°ƒè¯•æ•°æ®å·²ä¿å­˜: {safe_stage}")
        self._log(f"     - åŸå§‹å“åº”: {raw_file.name}")
        self._log(f"     - æå–ç»“æœ: {extracted_file.name}")

    def save_document(self, stage: str, document: str):
        """
        ä¿å­˜æ–‡æ¡£é˜¶æ®µçš„æ•°æ®

        Args:
            stage: é˜¶æ®µåç§°ï¼ˆå¦‚ "04_document"ï¼‰
            document: ç”Ÿæˆçš„æ–‡æ¡£å†…å®¹
        """
        if not self.enabled:
            return

        # æ¸…ç† stage åç§°ï¼Œæ›¿æ¢ä¸å®‰å…¨çš„æ–‡ä»¶åå­—ç¬¦
        import re
        safe_stage = re.sub(r'[^\w\-]', '_', stage)

        timestamp = self._get_timestamp()
        doc_file = self.debug_dir / f"{timestamp}_{safe_stage}.md"

        with open(doc_file, 'w', encoding='utf-8') as f:
            f.write(document)

        self._log(f"  ğŸ› è°ƒè¯•æ•°æ®å·²ä¿å­˜: {safe_stage}")
        self._log(f"     - ç”Ÿæˆæ–‡æ¡£: {doc_file.name}")

    def save_error(self, stage: str, error: Exception, context: Optional[dict] = None):
        """
        ä¿å­˜é”™è¯¯ä¿¡æ¯

        Args:
            stage: å‘ç”Ÿé”™è¯¯çš„é˜¶æ®µ
            error: å¼‚å¸¸å¯¹è±¡
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        """
        if not self.enabled:
            return

        # æ¸…ç† stage åç§°ï¼Œæ›¿æ¢ä¸å®‰å…¨çš„æ–‡ä»¶åå­—ç¬¦
        import re
        safe_stage = re.sub(r'[^\w\-]', '_', stage)

        timestamp = self._get_timestamp()
        error_file = self.debug_dir / f"{timestamp}_{safe_stage}_error.json"

        error_data = {
            "stage": stage,
            "error_type": type(error).__name__,
            "error_message": str(error),
            "timestamp": timestamp,
            "context": context or {}
        }

        with open(error_file, 'w', encoding='utf-8') as f:
            json.dump(error_data, f, ensure_ascii=False, indent=2)

        self._log(f"  ğŸ› é”™è¯¯ä¿¡æ¯å·²ä¿å­˜: {error_file.name}")

    @staticmethod
    def _get_timestamp() -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        return datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

    def _log(self, message: str):
        """è¾“å‡ºæ—¥å¿—"""
        if self.verbose:
            print(message)

    def load_cached_document(self, stage: str) -> Optional[str]:
        """
        åŠ è½½ç¼“å­˜çš„æ–‡æ¡£ï¼ˆMarkdown æ ¼å¼ï¼‰

        Args:
            stage: é˜¶æ®µåç§°ï¼ˆå¦‚ "04_document"ï¼‰

        Returns:
            ç¼“å­˜çš„æ–‡æ¡£å†…å®¹ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥åˆ™è¿”å› None
        """
        if not self.enabled or not self.debug_dir.exists():
            return None

        # æ¸…ç† stage åç§°ï¼Œæ›¿æ¢ä¸å®‰å…¨çš„æ–‡ä»¶åå­—ç¬¦
        import re
        safe_stage = re.sub(r'[^\w\-]', '_', stage)

        # æŸ¥æ‰¾æœ€æ–°çš„è¯¥é˜¶æ®µçš„ .md æ–‡ä»¶
        pattern = f"*_{safe_stage}.md"
        files = sorted(self.debug_dir.glob(pattern), reverse=True)

        if not files:
            return None

        latest_file = files[0]

        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                content = f.read()

            self._log(f"  ğŸ“¦ ä½¿ç”¨ç¼“å­˜æ–‡æ¡£: {latest_file.name}")
            return content
        except Exception as e:
            self._log(f"  âš ï¸  ç¼“å­˜è¯»å–å¤±è´¥: {e}")
            return None

    def load_cached_data(self, stage: str) -> Optional[dict]:
        """
        åŠ è½½ç¼“å­˜çš„åˆ†ææ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰

        Args:
            stage: é˜¶æ®µåç§°ï¼ˆå¦‚ "01_overview", "02_module_01"ï¼‰

        Returns:
            ç¼“å­˜çš„æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥åˆ™è¿”å› None
        """
        if not self.enabled or not self.debug_dir.exists():
            return None

        # æ¸…ç† stage åç§°ï¼Œæ›¿æ¢ä¸å®‰å…¨çš„æ–‡ä»¶åå­—ç¬¦
        import re
        safe_stage = re.sub(r'[^\w\-]', '_', stage)

        # æŸ¥æ‰¾æœ€æ–°çš„è¯¥é˜¶æ®µçš„ extracted.json æ–‡ä»¶
        pattern = f"*_{safe_stage}_extracted.json"
        files = sorted(self.debug_dir.glob(pattern), reverse=True)

        if not files:
            return None

        latest_file = files[0]

        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            self._log(f"  ğŸ“¦ ä½¿ç”¨ç¼“å­˜æ•°æ®: {latest_file.name}")
            return data
        except Exception as e:
            self._log(f"  âš ï¸  ç¼“å­˜è¯»å–å¤±è´¥: {e}")
            return None

    def get_debug_summary(self) -> dict:
        """
        è·å– debug æ–‡ä»¶æ‘˜è¦

        Returns:
            åŒ…å« debug æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        if not self.enabled or not self.debug_dir.exists():
            return {"enabled": False}

        files = list(self.debug_dir.glob("*"))

        # æŒ‰ç±»å‹ç»Ÿè®¡
        stats = {
            "enabled": True,
            "debug_dir": str(self.debug_dir),
            "total_files": len(files),
            "by_type": {
                "raw": len([f for f in files if f.name.endswith("_raw.txt")]),
                "extracted": len([f for f in files if f.name.endswith("_extracted.json")]),
                "documents": len([f for f in files if f.suffix == ".md"]),
                "errors": len([f for f in files if f.name.endswith("_error.json")]),
            }
        }

        return stats

    # ========================================================================
    # PRDæ–‡æ¡£ç”Ÿæˆç¼“å­˜ç›¸å…³æ–¹æ³•
    # ========================================================================

    def load_product_grouping(self) -> Optional[dict]:
        """
        åŠ è½½äº§å“åŠŸèƒ½åŸŸåˆ†ç»„ç¼“å­˜

        Returns:
            äº§å“åŠŸèƒ½åŸŸåˆ†ç»„ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥åˆ™è¿”å› None
        """
        grouping_file = self.debug_dir / "product_grouping.json"

        if not grouping_file.exists():
            return None

        try:
            with open(grouping_file, 'r', encoding='utf-8') as f:
                product_grouping = json.load(f)

            self._log(f"  ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„äº§å“åŠŸèƒ½åŸŸåˆ†ç»„")
            return product_grouping
        except Exception as e:
            self._log(f"  âš ï¸  åŠ è½½äº§å“åŠŸèƒ½åŸŸåˆ†ç»„å¤±è´¥: {str(e)}")
            return None

    def save_product_grouping(self, product_grouping: dict) -> bool:
        """
        ä¿å­˜äº§å“åŠŸèƒ½åŸŸåˆ†ç»„ç»“æœ

        Args:
            product_grouping: äº§å“åŠŸèƒ½åŸŸåˆ†ç»„ç»“æœ

        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        grouping_file = self.debug_dir / "product_grouping.json"

        try:
            with open(grouping_file, 'w', encoding='utf-8') as f:
                json.dump(product_grouping, f, ensure_ascii=False, indent=2)

            self._log(f"  ğŸ’¾ äº§å“åŠŸèƒ½åŸŸåˆ†ç»„å·²ä¿å­˜: {grouping_file.name}")
            return True
        except Exception as e:
            self._log(f"  âš ï¸  ä¿å­˜äº§å“åŠŸèƒ½åŸŸåˆ†ç»„å¤±è´¥: {str(e)}")
            return False

    def check_prd_exists(self, prd_dir: Path, domain_name: str) -> Optional[Path]:
        """
        æ£€æŸ¥PRDæ–‡æ¡£æ˜¯å¦å·²å­˜åœ¨

        Args:
            prd_dir: PRDè¾“å‡ºç›®å½•
            domain_name: åŠŸèƒ½åŸŸåç§°

        Returns:
            PRDæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™è¿”å› None
        """
        import re

        # å®‰å…¨åŒ–æ–‡ä»¶å
        safe_domain_name = re.sub(r'[^\w\-]', '_', domain_name)
        prd_file = prd_dir / f"{safe_domain_name}.md"

        if prd_file.exists():
            self._log(f"  ğŸ“¦ ä½¿ç”¨å·²æœ‰PRDæ–‡æ¡£: {safe_domain_name}.md")
            return prd_file

        return None

    def save_prd_document(self, prd_dir: Path, domain_name: str, content: str) -> Optional[Path]:
        """
        ä¿å­˜PRDæ–‡æ¡£

        Args:
            prd_dir: PRDè¾“å‡ºç›®å½•
            domain_name: åŠŸèƒ½åŸŸåç§°
            content: æ–‡æ¡£å†…å®¹

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        import re

        # å®‰å…¨åŒ–æ–‡ä»¶å
        safe_domain_name = re.sub(r'[^\w\-]', '_', domain_name)
        prd_file = prd_dir / f"{safe_domain_name}.md"

        try:
            with open(prd_file, 'w', encoding='utf-8') as f:
                f.write(content)

            self._log(f"  ğŸ’¾ PRDæ–‡æ¡£å·²ä¿å­˜: {safe_domain_name}.md")
            return prd_file
        except Exception as e:
            self._log(f"  âš ï¸  ä¿å­˜PRDæ–‡æ¡£å¤±è´¥: {str(e)}")
            return None

    # ========================================================================
    # æ‰¹æ¬¡åˆ†æç›¸å…³æ–¹æ³•
    # ========================================================================

    def find_latest_batch_directory(self, module_name: str) -> Optional[Path]:
        """
        æŸ¥æ‰¾æœ€æ–°çš„æ‰¹æ¬¡ç›®å½•

        Args:
            module_name: æ¨¡å—åç§°

        Returns:
            æœ€æ–°çš„æ‰¹æ¬¡ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        import re

        if not self.enabled or not self.debug_dir.exists():
            return None

        # æ¸…ç†æ¨¡å—åï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
        safe_module_name = re.sub(r'[^\w\-]', '_', module_name)

        # æŸ¥æ‰¾åŒ¹é…çš„æ‰¹æ¬¡ç›®å½•
        pattern = f"*_{safe_module_name}_batches"
        batch_dirs = sorted(self.debug_dir.glob(pattern), reverse=True)

        if batch_dirs:
            latest_dir = batch_dirs[0]
            self._log(f"  ğŸ“¦ æ‰¾åˆ°æ‰¹æ¬¡ç›®å½•: {latest_dir.name}")
            return latest_dir

        return None

    def create_batch_directory(self, module_name: str) -> Path:
        """
        åˆ›å»ºæ‰¹æ¬¡ä¸“ç”¨ç›®å½•ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™å¤ç”¨ï¼‰

        Args:
            module_name: æ¨¡å—åç§°

        Returns:
            æ‰¹æ¬¡ç›®å½•è·¯å¾„
        """
        import re

        if not self.enabled:
            # å³ä½¿ä¸å¯ç”¨debugï¼Œä¹Ÿè¿”å›ä¸€ä¸ªä¸´æ—¶ç›®å½•
            return self.debug_dir / "temp_batches"

        # å…ˆå°è¯•æŸ¥æ‰¾å·²æœ‰çš„æ‰¹æ¬¡ç›®å½•
        existing_dir = self.find_latest_batch_directory(module_name)
        if existing_dir:
            self._log(f"  ğŸ”„ å¤ç”¨æ‰¹æ¬¡ç›®å½•: {existing_dir.name}")
            return existing_dir

        # åˆ›å»ºæ—¶é—´æˆ³
        timestamp = self._get_timestamp()

        # æ¸…ç†æ¨¡å—åï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
        safe_module_name = re.sub(r'[^\w\-]', '_', module_name)

        # åˆ›å»ºæ‰¹æ¬¡ç›®å½•
        batch_dir = self.debug_dir / f"{timestamp}_{safe_module_name}_batches"
        batch_dir.mkdir(parents=True, exist_ok=True)

        self._log(f"  ğŸ“ åˆ›å»ºæ‰¹æ¬¡ç›®å½•: {batch_dir.name}")

        return batch_dir

    def load_batches_info(self, batch_dir: Path, module_name: str) -> Optional[list]:
        """
        åŠ è½½å·²ä¿å­˜çš„æ‰¹æ¬¡ä¿¡æ¯

        Args:
            batch_dir: æ‰¹æ¬¡ç›®å½•
            module_name: æ¨¡å—åç§°

        Returns:
            æ‰¹æ¬¡åˆ—è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥åˆ™è¿”å› None
        """
        if not self.enabled or not batch_dir.exists():
            return None

        # æ¸…ç†æ¨¡å—å
        import re
        safe_module_name = re.sub(r'[^\w\-]', '_', module_name)

        summary_file = batch_dir / f"{safe_module_name}_batches_summary.json"

        if not summary_file.exists():
            return None

        try:
            # åŠ è½½æ‰¹æ¬¡ç»Ÿè®¡ä¿¡æ¯
            with open(summary_file, 'r', encoding='utf-8') as f:
                summary = json.load(f)

            total_batches = summary.get('total_batches', 0)

            if total_batches == 0:
                return None

            # åŠ è½½æ¯ä¸ªæ‰¹æ¬¡çš„è¯¦ç»†ä¿¡æ¯
            batches = []
            for idx in range(1, total_batches + 1):
                batch_detail_file = batch_dir / f"{safe_module_name}_batch_{idx:02d}_info.json"

                if not batch_detail_file.exists():
                    self._log(f"  âš ï¸  æ‰¹æ¬¡{idx}è¯¦æƒ…æ–‡ä»¶ä¸å­˜åœ¨")
                    return None

                with open(batch_detail_file, 'r', encoding='utf-8') as f:
                    batch_info = json.load(f)
                    batches.append(batch_info)

            self._log(f"  ğŸ“¦ åŠ è½½æ‰¹æ¬¡ä¿¡æ¯: {len(batches)} ä¸ªæ‰¹æ¬¡")
            return batches

        except Exception as e:
            self._log(f"  âš ï¸  æ‰¹æ¬¡ä¿¡æ¯åŠ è½½å¤±è´¥: {e}")
            return None

    def save_batches_info(
        self, batch_dir: Path, module_name: str, batches: list, all_files: list
    ):
        """
        ä¿å­˜æ‰¹æ¬¡è¯¦æƒ…ä¿¡æ¯

        Args:
            batch_dir: æ‰¹æ¬¡ç›®å½•
            module_name: æ¨¡å—åç§°
            batches: æ‰¹æ¬¡åˆ—è¡¨
            all_files: æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯
        """
        if not self.enabled:
            return

        # æ¸…ç†æ¨¡å—å
        import re
        safe_module_name = re.sub(r'[^\w\-]', '_', module_name)

        # å‡†å¤‡æ‰¹æ¬¡ç»Ÿè®¡ä¿¡æ¯
        batches_summary = {
            "total_batches": len(batches),
            "total_files": len(all_files),
            "batches": []
        }

        for idx, batch in enumerate(batches, 1):
            batch_info = {
                "batch_id": idx,
                "file_count": len(batch['files']),
                "estimated_tokens": batch['estimated_tokens'],
                "cohesion": batch['cohesion'],
                "description": batch['description'],
                "file_paths": [f['path'] for f in batch['files']]
            }
            batches_summary["batches"].append(batch_info)

            # ä¿å­˜æ¯ä¸ªæ‰¹æ¬¡çš„è¯¦ç»†ä¿¡æ¯ï¼ˆæ–‡ä»¶ååŒ…å«æ¨¡å—åï¼‰
            batch_detail_file = batch_dir / f"{safe_module_name}_batch_{idx:02d}_info.json"
            with open(batch_detail_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "batch_id": idx,
                    "files": batch['files'],
                    "estimated_tokens": batch['estimated_tokens'],
                    "cohesion": batch['cohesion'],
                    "description": batch['description']
                }, f, ensure_ascii=False, indent=2)

        # ä¿å­˜æ‰¹æ¬¡ç»Ÿè®¡ï¼ˆæ–‡ä»¶ååŒ…å«æ¨¡å—åï¼‰
        summary_file = batch_dir / f"{safe_module_name}_batches_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(batches_summary, f, ensure_ascii=False, indent=2)

        self._log(f"  ğŸ“Š æ‰¹æ¬¡ä¿¡æ¯å·²ä¿å­˜: {len(batches)} ä¸ªæ‰¹æ¬¡")

    def save_batch_result(
        self,
        batch_dir: Path,
        module_name: str,
        batch_idx: int,
        response_text: str,
        batch_result: dict,
        batch_info: dict
    ):
        """
        ä¿å­˜å•ä¸ªæ‰¹æ¬¡çš„åˆ†æç»“æœ

        Args:
            batch_dir: æ‰¹æ¬¡ç›®å½•
            module_name: æ¨¡å—åç§°
            batch_idx: æ‰¹æ¬¡ç´¢å¼•
            response_text: AIåŸå§‹å“åº”
            batch_result: æå–çš„JSONç»“æœ
            batch_info: æ‰¹æ¬¡ä¿¡æ¯
        """
        if not self.enabled:
            return

        # æ¸…ç†æ¨¡å—å
        import re
        safe_module_name = re.sub(r'[^\w\-]', '_', module_name)

        # ä¿å­˜åŸå§‹å“åº”ï¼ˆæ–‡ä»¶ååŒ…å«æ¨¡å—åï¼‰
        raw_file = batch_dir / f"{safe_module_name}_batch_{batch_idx:02d}_raw.txt"
        with open(raw_file, 'w', encoding='utf-8') as f:
            f.write(response_text)

        # ä¿å­˜æå–çš„ç»“æœï¼ˆæ–‡ä»¶ååŒ…å«æ¨¡å—åï¼‰
        result_file = batch_dir / f"{safe_module_name}_batch_{batch_idx:02d}_result.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(batch_result, f, ensure_ascii=False, indent=2)

        self._log(f"  ğŸ’¾ æ‰¹æ¬¡{batch_idx}ç»“æœå·²ä¿å­˜")

    def load_batch_result(self, batch_dir: Path, module_name: str, batch_idx: int) -> dict:
        """
        åŠ è½½å·²ä¿å­˜çš„æ‰¹æ¬¡ç»“æœ

        Args:
            batch_dir: æ‰¹æ¬¡ç›®å½•
            module_name: æ¨¡å—åç§°
            batch_idx: æ‰¹æ¬¡ç´¢å¼•

        Returns:
            æ‰¹æ¬¡ç»“æœå­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥åˆ™è¿”å› None
        """
        if not self.enabled:
            return None

        # æ¸…ç†æ¨¡å—å
        import re
        safe_module_name = re.sub(r'[^\w\-]', '_', module_name)

        result_file = batch_dir / f"{safe_module_name}_batch_{batch_idx:02d}_result.json"

        if not result_file.exists():
            return None

        try:
            with open(result_file, 'r', encoding='utf-8') as f:
                batch_result = json.load(f)

            self._log(f"  ğŸ“¦ åŠ è½½æ‰¹æ¬¡{batch_idx}ç¼“å­˜")
            return batch_result
        except Exception as e:
            self._log(f"  âš ï¸  æ‰¹æ¬¡{batch_idx}ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            return None

