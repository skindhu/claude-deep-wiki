"""
Structure Validator - ç»“æ„æ‰«æéªŒè¯å™¨

è´Ÿè´£éªŒè¯ç»“æ„æ‰«æç»“æœçš„å®Œæ•´æ€§ï¼Œè¯†åˆ«å’Œä¿®å¤å­¤ç«‹æ–‡ä»¶
"""

from typing import Dict, Any, List, Optional
from pathlib import Path
from utils.claude_query_helper import ClaudeQueryHelper
from utils.structure_prompt_builder import StructurePromptBuilder


class StructureValidator:
    """ç»“æ„æ‰«æéªŒè¯å™¨"""

    def __init__(self, client=None, prompt_builder: Optional[StructurePromptBuilder] = None):
        """
        åˆå§‹åŒ–éªŒè¯å™¨

        Args:
            client: Claude SDK Clientï¼ˆç”¨äºæ™ºèƒ½ä¿®å¤ï¼‰
            prompt_builder: StructurePromptBuilder å®ä¾‹
        """
        self.client = client
        self.prompt_builder = prompt_builder
        self.claude_helper = ClaudeQueryHelper()
        self.last_response = None  # ä¿å­˜æœ€åä¸€æ¬¡ Claude è°ƒç”¨çš„åŸå§‹å“åº”

    @staticmethod
    def _normalize_path(path: str) -> str:
        """
        è§„èŒƒåŒ–æ–‡ä»¶è·¯å¾„ï¼Œç¡®ä¿è·¯å¾„æ ¼å¼ä¸€è‡´

        Args:
            path: åŸå§‹è·¯å¾„

        Returns:
            è§„èŒƒåŒ–åçš„è·¯å¾„
        """
        if not path:
            return ""

        # å»é™¤å‰å¯¼ ./
        path = path.lstrip('./')

        # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
        path = path.replace('\\', '/')

        # å»é™¤å°¾éƒ¨æ–œæ 
        path = path.rstrip('/')

        return path

    def validate_file_coverage(
        self,
        structure_overview: Dict[str, Any],
        repo_path: str,
        include_sub_modules: bool = False
    ) -> Dict[str, Any]:
        """
        éªŒè¯æ–‡ä»¶è¦†ç›–ç‡ï¼Œè¯†åˆ«é—æ¼çš„æ–‡ä»¶

        âš ï¸ é˜¶æ®µ1/2ç®€åŒ–ç‰ˆï¼šé»˜è®¤åªéªŒè¯ä¸€çº§æ¨¡å—ï¼Œä¸é€’å½’ sub_modules
        âš ï¸ é˜¶æ®µ4å®Œæ•´ç‰ˆï¼šå¯è®¾ç½® include_sub_modules=True é€’å½’éªŒè¯æ‰€æœ‰å­æ¨¡å—

        Args:
            structure_overview: ç»“æ„æ¦‚è§ˆ
            repo_path: ä»“åº“è·¯å¾„
            include_sub_modules: æ˜¯å¦é€’å½’æ”¶é›† sub_modules çš„æ–‡ä»¶ï¼ˆé»˜è®¤ Falseï¼‰

        Returns:
            {
                "total_scanned": int,
                "total_in_modules": int,
                "orphan_files": [...],
                "coverage_rate": float,
                "scan_result": {...}
            }
        """
        # è·å–å®Œæ•´çš„æ–‡ä»¶æ‰«æåˆ—è¡¨
        from mcp_servers.code_analysis_server import scan_repository_structure

        scan_result = scan_repository_structure(repo_path)

        if not scan_result.get('success'):
            return {
                "total_scanned": 0,
                "total_in_modules": 0,
                "orphan_files": [],
                "coverage_rate": 0.0,
                "scan_result": scan_result
            }

        # æ”¶é›†æ‰«æåˆ°çš„æ‰€æœ‰æ–‡ä»¶è·¯å¾„ï¼ˆscan_repository_structure å·²è¿‡æ»¤ï¼Œåªæœ‰æºç å’Œé…ç½®æ–‡ä»¶ï¼‰
        # è·¯å¾„è§„èŒƒåŒ–ï¼šå»é™¤å‰å¯¼ ./ å¹¶ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ 
        scanned_files = {
            self._normalize_path(f['path'])
            for f in scan_result.get('files', [])
        }

        # æ”¶é›†æ¨¡å—ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        module_files = set()
        duplicate_files = []  # è®°å½•é‡å¤åˆ†é…çš„æ–‡ä»¶
        modules = structure_overview.get('modules', [])

        for module in modules:
            module_name = module.get('name', 'Unknown')

            # æ”¶é›†ä¸€çº§æ¨¡å—çš„ all_files
            all_files = module.get('all_files')
            if all_files:  # ç¡®ä¿ä¸æ˜¯ None
                for file_path in all_files:
                    if file_path:  # ç¡®ä¿è·¯å¾„ä¸ä¸ºç©º
                        normalized = self._normalize_path(file_path)
                        if normalized in module_files:
                            duplicate_files.append(f"{file_path} (åœ¨ {module_name} ä¸­)")
                        module_files.add(normalized)

            # å¦‚æœéœ€è¦ï¼Œé€’å½’æ”¶é›† sub_modules çš„æ–‡ä»¶
            if include_sub_modules:
                sub_modules = module.get('sub_modules', [])
                for sub_module in sub_modules:
                    sub_module_name = sub_module.get('name', 'Unknown')
                    sub_files = sub_module.get('all_files')
                    if sub_files:
                        for file_path in sub_files:
                            if file_path:
                                normalized = self._normalize_path(file_path)
                                if normalized in module_files:
                                    duplicate_files.append(f"{file_path} (åœ¨ {module_name}.{sub_module_name} ä¸­)")
                                module_files.add(normalized)

        # å¦‚æœå‘ç°é‡å¤æ–‡ä»¶ï¼Œè­¦å‘Š
        if duplicate_files:
            print(f"     âš ï¸  è­¦å‘Šï¼šå‘ç° {len(duplicate_files)} ä¸ªé‡å¤åˆ†é…çš„æ–‡ä»¶")
            for dup in duplicate_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"        - {dup}")

        # è¯†åˆ«å­¤ç«‹æ–‡ä»¶ï¼ˆåªåœ¨ä»£ç æ–‡ä»¶ä¸­æŸ¥æ‰¾ï¼‰
        orphan_file_paths = scanned_files - module_files

        # æ„å»ºå­¤ç«‹æ–‡ä»¶è¯¦ç»†ä¿¡æ¯ï¼ˆscan_repository_structure å·²è¿‡æ»¤ï¼‰
        orphan_files = []
        for file_info in scan_result.get('files', []):
            normalized_path = self._normalize_path(file_info['path'])
            if normalized_path in orphan_file_paths:
                orphan_files.append(file_info)

        # è®¡ç®—è¦†ç›–ç‡ï¼ˆæºç  + é…ç½®æ–‡ä»¶ï¼‰
        total_scanned = len(scanned_files)
        total_in_modules = len(module_files)
        coverage_rate = total_in_modules / total_scanned if total_scanned > 0 else 0.0

        return {
            "total_scanned": total_scanned,
            "total_in_modules": total_in_modules,
            "orphan_files": orphan_files,
            "coverage_rate": coverage_rate,
            "scan_result": scan_result
        }

    def _batch_orphan_files_by_tokens(
        self,
        orphan_files: List[Dict[str, Any]],
        max_tokens_per_batch: int = 40000,
        max_files_per_batch: int = 200
    ) -> List[List[Dict[str, Any]]]:
        """
        æŒ‰ token å’Œæ–‡ä»¶æ•°é‡é™åˆ¶åˆ†æ‰¹å­¤ç«‹æ–‡ä»¶

        Args:
            orphan_files: å­¤ç«‹æ–‡ä»¶åˆ—è¡¨
            max_tokens_per_batch: æ¯æ‰¹çš„æœ€å¤§ token æ•°ï¼ˆé»˜è®¤ 40kï¼‰
            max_files_per_batch: æ¯æ‰¹çš„æœ€å¤§æ–‡ä»¶æ•°ï¼ˆé»˜è®¤ 200ï¼‰

        Returns:
            åˆ†æ‰¹åçš„æ–‡ä»¶åˆ—è¡¨
        """
        from utils.token_counter import count_tokens
        import json

        batches = []
        current_batch = []
        current_tokens = 0

        for file_info in orphan_files:
            # ç®€åŒ–æ–‡ä»¶ä¿¡æ¯ï¼Œåªä¿ç•™å¿…è¦å­—æ®µä»¥å‡å°‘ token
            simplified_info = {
                'path': file_info.get('path'),
                'language': file_info.get('language'),
                'category': file_info.get('category')
            }

            # è®¡ç®—å•ä¸ªæ–‡ä»¶ä¿¡æ¯çš„ token æ•°
            file_json = json.dumps(simplified_info, ensure_ascii=False)
            file_tokens = count_tokens(file_json)

            # å¦‚æœåŠ å…¥å½“å‰æ‰¹æ¬¡ä¼šè¶…é™ï¼ˆtoken æˆ–æ–‡ä»¶æ•°é‡ï¼‰ï¼Œå¼€å§‹æ–°æ‰¹æ¬¡
            if current_batch and (
                current_tokens + file_tokens > max_tokens_per_batch or
                len(current_batch) >= max_files_per_batch
            ):
                batches.append(current_batch)
                current_batch = []
                current_tokens = 0

            current_batch.append(file_info)
            current_tokens += file_tokens

        # æ·»åŠ æœ€åä¸€æ‰¹
        if current_batch:
            batches.append(current_batch)

        return batches

    async def fix_orphan_files_with_claude(
        self,
        structure_overview: Dict[str, Any],
        orphan_files: List[Dict[str, Any]],
        repo_path: str
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ Claude æ™ºèƒ½åˆ†æå¹¶ä¿®å¤å­¤ç«‹æ–‡ä»¶ï¼ˆæ”¯æŒåˆ†æ‰¹å¤„ç†ï¼‰

        Args:
            structure_overview: å½“å‰æ¨¡å—ç»“æ„
            orphan_files: å­¤ç«‹æ–‡ä»¶åˆ—è¡¨
            repo_path: ä»“åº“è·¯å¾„

        Returns:
            æ›´æ–°åçš„ structure_overview
        """
        if not orphan_files:
            return structure_overview

        # æŒ‰ token å’Œæ–‡ä»¶æ•°é‡é™åˆ¶åˆ†æ‰¹
        batches = self._batch_orphan_files_by_tokens(
            orphan_files,
            max_tokens_per_batch=40000,
            max_files_per_batch=400
        )
        total_batches = len(batches)

        # æ‰“å°åˆ†æ‰¹ä¿¡æ¯
        print(f"        ğŸ“¦ åˆ†æ‰¹å¤„ç†: å…± {len(orphan_files)} ä¸ªå­¤ç«‹æ–‡ä»¶ï¼Œåˆ†ä¸º {total_batches} æ‰¹")
        print(f"           é™åˆ¶: æ¯æ‰¹æœ€å¤š 200 ä¸ªæ–‡ä»¶ æˆ– 40k tokens")
        for i, batch in enumerate(batches, 1):
            print(f"           æ‰¹æ¬¡ {i}: {len(batch)} ä¸ªæ–‡ä»¶")

        # æ”¶é›†æ‰€æœ‰æ‰¹æ¬¡çš„ assignments
        all_assignments = []
        total_tokens = 0

        from utils.token_counter import count_tokens

        # é€æ‰¹å¤„ç†
        for batch_idx, batch in enumerate[List[Dict[str, Any]]](batches, 1):
            print(f"        â†’ å¤„ç†æ‰¹æ¬¡ {batch_idx}/{total_batches}...")

            # æ„å»ºè¯¥æ‰¹çš„æç¤ºè¯
            prompt = self.prompt_builder.build_orphan_files_fix_prompt(
                structure_overview.get('modules', []),
                batch,
                repo_path
            )

            # ç»Ÿè®¡å½“å‰æ‰¹æ¬¡çš„ token æ•°é‡
            batch_tokens = count_tokens(prompt)
            total_tokens += batch_tokens
            print(f"           ğŸ¯ æ‰¹æ¬¡ {batch_idx} Token: {batch_tokens:,} tokens")

            # å®šä¹‰ validatorï¼šç¡®ä¿åˆ†é…çš„æ–‡ä»¶æ•°é‡å’Œå½“å‰æ‰¹æ¬¡çš„å­¤ç«‹æ–‡ä»¶æ•°é‡ç›¸è¿‘
            def validate_assignments(result, current_batch=batch):
                if not result or not result.get('assignments'):
                    return False

                assignments = result.get('assignments', [])
                assigned_files = {a.get('file') for a in assignments if a.get('file')}
                batch_file_paths = {f['path'] for f in current_batch}

                # æ£€æŸ¥è¦†ç›–ç‡ï¼šè‡³å°‘è¦è¦†ç›– 90% çš„å½“å‰æ‰¹æ¬¡æ–‡ä»¶
                coverage = len(assigned_files & batch_file_paths) / len(batch_file_paths) if batch_file_paths else 0
                if coverage < 0.9:
                    print(f"              âš ï¸  æ‰¹æ¬¡ {batch_idx} åˆ†é…è¦†ç›–ç‡ä¸è¶³: {coverage:.1%}ï¼Œé‡è¯•ä¸­...")
                    return False

                return True

            # è°ƒç”¨ Claude è¿›è¡Œæ™ºèƒ½åˆ†æï¼ˆé”™è¯¯å¤„ç†åœ¨ ClaudeQueryHelper å†…éƒ¨å®Œæˆï¼‰
            response_text, fix_result = await ClaudeQueryHelper.query_with_json_retry(
                client=self.client,
                prompt=prompt,
                session_id=f"structure_scan_orphan_fix_batch_{batch_idx}",
                max_attempts=3,
                validator=validate_assignments
            )

            # æ”¶é›†è¯¥æ‰¹æ¬¡çš„ assignments
            batch_assignments = fix_result.get('assignments', [])
            all_assignments.extend(batch_assignments)
            print(f"           âœ“ æ‰¹æ¬¡ {batch_idx} å®Œæˆ: {len(batch_assignments)} ä¸ªåˆ†é…")

        # æ‰“å°æ€»è®¡ä¿¡æ¯
        print(f"        ğŸ“Š æ€»è®¡: {total_batches} æ‰¹æ¬¡, {total_tokens:,} tokens, {len(all_assignments)} ä¸ªåˆ†é…")

        # ç»Ÿä¸€åº”ç”¨æ‰€æœ‰ä¿®å¤å»ºè®®
        structure_overview = self.apply_fix_assignments(
            structure_overview,
            all_assignments
        )

        return structure_overview

    def apply_fix_assignments(
        self,
        structure_overview: Dict[str, Any],
        assignments: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        åº”ç”¨ Claude çš„ä¿®å¤å»ºè®®

        Args:
            structure_overview: å½“å‰ç»“æ„
            assignments: Claude çš„åˆ†é…å»ºè®®

        Returns:
            æ›´æ–°åçš„ç»“æ„
        """
        modules = structure_overview.get('modules', [])

        # ç»Ÿè®¡å„ç§æ“ä½œ
        assigned_count = 0
        new_modules_count = 0
        other_count = 0

        for assignment in assignments:
            action = assignment.get('action')
            file_path = assignment.get('file')

            if not file_path:
                continue

            if action == 'assign_to_existing':
                # åˆ†é…åˆ°ç°æœ‰æ¨¡å—
                target_module = assignment.get('target_module')
                for module in modules:
                    if module.get('name') == target_module:
                        if 'all_files' not in module:
                            module['all_files'] = []
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆè€ƒè™‘è·¯å¾„è§„èŒƒåŒ–ï¼‰
                        normalized_existing = [self._normalize_path(f) for f in module['all_files']]
                        if self._normalize_path(file_path) not in normalized_existing:
                            module['all_files'].append(file_path)
                        assigned_count += 1
                        break

            elif action == 'create_new_module':
                # åˆ›å»ºæ–°æ¨¡å—
                new_module = assignment.get('new_module', {})
                if new_module:
                    # ç¡®ä¿æ–°æ¨¡å—æœ‰å¿…è¦çš„å­—æ®µ
                    if 'all_files' not in new_module:
                        new_module['all_files'] = []
                    if 'key_files_paths' not in new_module:
                        new_module['key_files_paths'] = []
                    if 'sub_modules' not in new_module:
                        new_module['sub_modules'] = []
                    modules.append(new_module)
                    new_modules_count += 1

            elif action == 'assign_to_other':
                # å½’å…¥"å…¶ä»–æ–‡ä»¶"æ¨¡å—
                other_module = self.get_or_create_other_module(modules)
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆè€ƒè™‘è·¯å¾„è§„èŒƒåŒ–ï¼‰
                normalized_existing = [self._normalize_path(f) for f in other_module['all_files']]
                if self._normalize_path(file_path) not in normalized_existing:
                    other_module['all_files'].append(file_path)
                other_count += 1

        # æ‰“å°ä¿®å¤æ‘˜è¦
        if assigned_count > 0:
            print(f"        âœ“ åˆ†é…åˆ°ç°æœ‰æ¨¡å—: {assigned_count} ä¸ªæ–‡ä»¶")
        if new_modules_count > 0:
            print(f"        âœ“ åˆ›å»ºæ–°æ¨¡å—: {new_modules_count} ä¸ª")
        if other_count > 0:
            print(f"        âœ“ å½’å…¥å…¶ä»–æ–‡ä»¶: {other_count} ä¸ªæ–‡ä»¶")

        structure_overview['modules'] = modules
        return structure_overview

    @staticmethod
    def get_or_create_other_module(modules: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è·å–æˆ–åˆ›å»º"å…¶ä»–æ–‡ä»¶"æ¨¡å—

        Args:
            modules: æ¨¡å—åˆ—è¡¨

        Returns:
            "å…¶ä»–æ–‡ä»¶"æ¨¡å—
        """
        # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨
        for module in modules:
            if module.get('name') == 'å…¶ä»–æ–‡ä»¶':
                return module

        # åˆ›å»ºæ–°çš„"å…¶ä»–æ–‡ä»¶"æ¨¡å—
        other_module = {
            "name": "å…¶ä»–æ–‡ä»¶",
            "layer_guess": "utils",
            "responsibility": "æœªåˆ†ç±»çš„é…ç½®æ–‡ä»¶ã€è„šæœ¬å’Œå…¶ä»–è¾…åŠ©æ–‡ä»¶",
            "all_files": [],
            "key_files_paths": [],
            "sub_modules": []
        }
        modules.append(other_module)
        return other_module

    def _collect_all_files(self, structure_overview: Dict[str, Any]) -> List[str]:
        """
        æ”¶é›†ç»“æ„ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆç”¨äºè®¡ç®—æ€»æ–‡ä»¶æ•°ï¼‰

        é€’å½’æ”¶é›†æ‰€æœ‰æ¨¡å—å’Œå­æ¨¡å—ä¸­çš„æ–‡ä»¶

        Args:
            structure_overview: ç»“æ„æ¦‚è§ˆ

        Returns:
            æ‰€æœ‰æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        all_files = []

        def collect_from_module(module):
            all_files.extend(module.get('all_files', []))
            for sub in module.get('sub_modules', []):
                collect_from_module(sub)

        for module in structure_overview.get('modules', []):
            collect_from_module(module)

        return all_files

    def detect_large_modules(
        self,
        structure_overview: Dict[str, Any],
        relative_threshold: float = 0.10,  # ç›¸å¯¹é˜ˆå€¼ï¼š20%
        min_threshold: int = 5,           # ç»å¯¹ä¸‹é™
        max_threshold: int = 30           # ç»å¯¹ä¸Šé™
    ) -> List[Dict[str, Any]]:
        """
        æ£€æµ‹éœ€è¦ç»†åˆ†çš„å¤§æ¨¡å—ï¼ˆç»¼åˆåˆ¤æ–­ç­–ç•¥ï¼‰

        ç­–ç•¥ï¼š
        1. è®¡ç®—ç›¸å¯¹é˜ˆå€¼ï¼ˆæ€»æ–‡ä»¶æ•° * relative_thresholdï¼‰
        2. é™åˆ¶åœ¨ [min_threshold, max_threshold] èŒƒå›´å†…
        3. æ–‡ä»¶æ•° > é˜ˆå€¼çš„æ¨¡å—éœ€è¦ç»†åˆ†

        Args:
            structure_overview: ç»“æ„æ¦‚è§ˆ
            relative_threshold: ç›¸å¯¹é˜ˆå€¼ï¼ˆé»˜è®¤ 0.20ï¼Œå³ 20%ï¼‰
            min_threshold: ç»å¯¹ä¸‹é™ï¼ˆé»˜è®¤ 20 æ–‡ä»¶ï¼‰
            max_threshold: ç»å¯¹ä¸Šé™ï¼ˆé»˜è®¤ 60 æ–‡ä»¶ï¼‰

        Returns:
            éœ€è¦ç»†åˆ†çš„å¤§æ¨¡å—åˆ—è¡¨
        """
        # è®¡ç®—æ€»æ–‡ä»¶æ•°
        total_files = len(self._collect_all_files(structure_overview))

        # è®¡ç®—åŠ¨æ€é˜ˆå€¼
        threshold = int(total_files * relative_threshold)
        threshold = max(min_threshold, min(threshold, max_threshold))

        print(f"        ğŸ“Š ç»†åˆ†ç­–ç•¥: é˜ˆå€¼ = {threshold} æ–‡ä»¶")
        print(f"           ï¼ˆæ€»æ–‡ä»¶: {total_files}, ç›¸å¯¹: {relative_threshold*100:.0f}%, èŒƒå›´: [{min_threshold}, {max_threshold}]ï¼‰")

        large_modules = []

        def check_module(module, parent_path=[]):
            file_count = len(module.get('all_files', []))
            if file_count > threshold:
                large_modules.append({
                    "module_path": parent_path + [module['name']],
                    "module_name": module['name'],
                    "file_count": file_count,
                    "all_files": module['all_files'],
                    "module_ref": module,
                    "threshold": threshold
                })

            # é€’å½’æ£€æŸ¥å­æ¨¡å—
            for sub in module.get('sub_modules', []):
                check_module(sub, parent_path + [module['name']])

        for module in structure_overview.get('modules', []):
            check_module(module)

        return large_modules

    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # é˜¶æ®µ3ï¼šå¤§æ¨¡å—æ™ºèƒ½ç»†åˆ†çš„æ–°æ–¹æ³•
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

    async def plan_module_subdivision(
        self,
        large_module: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        é˜¶æ®µ3.1ï¼šè§„åˆ’å­æ¨¡å—ç»†åˆ†ï¼ˆåªè§„åˆ’ï¼Œä¸åˆ†é…æ‰€æœ‰æ–‡ä»¶ï¼‰

        Args:
            large_module: å¤§æ¨¡å—ä¿¡æ¯ {
                'module_name': str,
                'module_path': List[str],
                'module_ref': Dict,
                'file_count': int,
                'all_files': List[str]
            }

        Returns:
            å­æ¨¡å—è§„åˆ’åˆ—è¡¨ [
                {
                    'name': str,
                    'description': str,
                    'suggested_key_files': List[str],
                    'suggested_entry_files': List[str]
                },
                ...
            ]
        """
        print(f"        â†’ 3.1: è§„åˆ’å­æ¨¡å—...")

        # æ„å»º prompt
        prompt = self.prompt_builder.build_module_subdivision_planning_prompt(
            module_info=large_module,
            repo_path=self._get_repo_path()
        )

        # éªŒè¯å™¨ï¼šæ£€æŸ¥è§„åˆ’ç»“æœçš„ç»“æ„
        all_files_set = set(large_module['all_files'])

        def validate_planning(result):
            if not result or not isinstance(result, dict):
                return False

            sub_modules = result.get('sub_modules', [])
            if not sub_modules or not isinstance(sub_modules, list):
                print(f"           âš ï¸  ç¼ºå°‘ sub_modules å­—æ®µæˆ–æ ¼å¼é”™è¯¯")
                return False

            if len(sub_modules) < 1:
                print(f"           âš ï¸  å­æ¨¡å—æ•°é‡ä¸åˆç†: {len(sub_modules)}ï¼ˆå»ºè®® 1-15 ä¸ªï¼‰")
                return False

            for idx, sub in enumerate(sub_modules, 1):
                # æ£€æŸ¥å¿…éœ€å­—æ®µ
                if not sub.get('name'):
                    print(f"           âš ï¸  å­æ¨¡å— {idx} ç¼ºå°‘ name å­—æ®µ")
                    return False

                if not sub.get('description'):
                    print(f"           âš ï¸  å­æ¨¡å— {idx} ({sub['name']}) ç¼ºå°‘ description å­—æ®µ")
                    return False

                # æ£€æŸ¥å»ºè®®çš„æ–‡ä»¶è·¯å¾„æ˜¯å¦å­˜åœ¨
                suggested_key = sub.get('suggested_key_files', [])
                suggested_entry = sub.get('suggested_entry_files', [])

                if not suggested_key and not suggested_entry:
                    print(f"           âš ï¸  å­æ¨¡å— {idx} ({sub['name']}) æ²¡æœ‰å»ºè®®ä»»ä½•å…³é”®æ–‡ä»¶")
                    return False

            return True

        # è°ƒç”¨ Claude è·å–è§„åˆ’ï¼ˆä½¿ç”¨å›ºåŒ–çš„ session_id ä¿æŒä¸Šä¸‹æ–‡è¿è´¯ï¼‰
        response_text, result = await self.claude_helper.query_with_json_retry(
            client=self.client,
            prompt=prompt,
            session_id="subdivision_planning",
            max_attempts=3,
            validator=validate_planning
        )

        # ä¿å­˜åŸå§‹å“åº”
        self.last_response = response_text

        subdivision_plan = result.get('sub_modules', [])

        print(f"           âœ“ è§„åˆ’å®Œæˆï¼Œå…± {len(subdivision_plan)} ä¸ªå­æ¨¡å—")
        for idx, sub in enumerate(subdivision_plan, 1):
            key_count = len(sub.get('suggested_key_files', []))
            entry_count = len(sub.get('suggested_entry_files', []))
            print(f"              {idx}. {sub['name']} (key:{key_count}, entry:{entry_count})")

        return subdivision_plan

    async def assign_files_by_dependency(
        self,
        parent_module: Dict[str, Any],
        subdivision_plan: List[Dict[str, Any]],
        repo_path: str
    ) -> List[Dict[str, Any]]:
        """
        é˜¶æ®µ3.2ï¼šä¾èµ–é©±åŠ¨çš„æ–‡ä»¶å½’å±ï¼ˆè‡ªåŠ¨åˆ†é… + å¾ªç¯ä¾èµ–å¤„ç†ï¼‰

        Args:
            parent_module: çˆ¶æ¨¡å—ä¿¡æ¯
            subdivision_plan: å­æ¨¡å—è§„åˆ’
            repo_path: ä»“åº“æ ¹è·¯å¾„

        Returns:
            å¸¦æœ‰ all_files çš„å­æ¨¡å—åˆ—è¡¨
        """
        print(f"        â†’ 3.2: ä¾èµ–é©±åŠ¨çš„æ–‡ä»¶å½’å±...")

        # åˆå§‹åŒ–ä¾èµ–åˆ†æå™¨
        from utils.dependency_analyzer import (
            DependencyAnalyzer,
            resolve_circular_conflicts
        )
        analyzer = DependencyAnalyzer()

        # æ­¥éª¤1ï¼šæ„å»ºä¾èµ–å›¾
        all_files = parent_module['all_files']
        dependency_graph = analyzer.build_dependency_graph(all_files, repo_path)

        # æ­¥éª¤2ï¼šæ£€æµ‹å¾ªç¯ä¾èµ–
        circular_groups = analyzer.detect_circular_dependencies(dependency_graph)

        # æ­¥éª¤3ï¼šä¸ºæ¯ä¸ªå­æ¨¡å—åˆæ­¥æ”¶é›†æ–‡ä»¶
        module_base_path = self._extract_module_base_path(parent_module)

        for sub_module in subdivision_plan:
            # åˆå¹¶ suggested_entry_files å’Œ suggested_key_files ä½œä¸ºèµ·ç‚¹
            start_files = list(set(
                sub_module.get('suggested_entry_files', []) +
                sub_module.get('suggested_key_files', [])
            ))

            # BFS éå†ä¾èµ–
            code_files = await analyzer.traverse_dependencies(
                start_files=start_files,
                dependency_graph=dependency_graph,
                max_depth=20,
                scope_pattern=module_base_path
            )

            # åˆæ­¥æ–‡ä»¶åˆ—è¡¨
            sub_module['preliminary_files'] = list(code_files)

            print(f"           â€¢ {sub_module['name']}: {len(code_files)} ä¸ªæ–‡ä»¶ï¼ˆä¾èµ–éå†ï¼‰")

        # æ­¥éª¤4ï¼šè§£å†³å¾ªç¯ä¾èµ–å†²çª
        if circular_groups:
            resolve_circular_conflicts(
                sub_modules=subdivision_plan,
                circular_groups=circular_groups,
                dependency_graph=dependency_graph
            )

        # æ­¥éª¤5ï¼šè¡¥å……é…ç½®/èµ„æºæ–‡ä»¶ï¼ˆè·¯å¾„åŒ¹é…ï¼‰
        assigned_files = set()
        for sub_module in subdivision_plan:
            assigned_files.update(sub_module['preliminary_files'])

        orphan_files = [f for f in all_files if f not in assigned_files]

        print(f"           â„¹ï¸  ä¾èµ–éå†åå‰©ä½™ {len(orphan_files)} ä¸ªæœªåˆ†é…æ–‡ä»¶")

        # for sub_module in subdivision_plan:
        #     # æ ¹æ®è·¯å¾„å…³é”®è¯åŒ¹é…é…ç½®æ–‡ä»¶
        #     config_files = analyzer.match_config_files_by_path(
        #         sub_module_name=sub_module['name'],
        #         orphan_files=orphan_files,
        #         module_base_path=module_base_path
        #     )

        #     if config_files:
        #         sub_module['preliminary_files'].extend(config_files)
        #         assigned_files.update(config_files)
        #         print(f"           â€¢ {sub_module['name']}: +{len(config_files)} ä¸ªé…ç½®æ–‡ä»¶ï¼ˆè·¯å¾„åŒ¹é…ï¼‰")

        # æ­¥éª¤6ï¼šæŒ‰ä¾èµ–é¡ºåºæ’åºå¹¶æ¸…ç†å­—æ®µ
        for sub_module in subdivision_plan:
            # ä½¿ç”¨æ‹“æ‰‘æ’åº
            preliminary_files_list = list(sub_module.pop('preliminary_files'))
            sub_module['all_files'] = analyzer.topological_sort_files(
                preliminary_files_list,
                dependency_graph
            )

            # ç§»é™¤ä¸´æ—¶å­—æ®µ
            sub_module.pop('suggested_key_files', None)
            sub_module.pop('suggested_entry_files', None)

        print(f"           âœ“ æ–‡ä»¶å½’å±å®Œæˆ")

        return subdivision_plan

    async def verify_subdivision_with_claude(
        self,
        parent_module: Dict[str, Any],
        auto_assigned_sub_modules: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        é˜¶æ®µ3.3ï¼šå¤„ç†æœªåˆ†é…æ–‡ä»¶ï¼Œå°†å…¶ä¿ç•™åœ¨çˆ¶æ¨¡å—

        æœªåˆ†é…çš„æ–‡ä»¶ï¼ˆæ²¡æœ‰ä¾èµ–å…³ç³»ï¼‰ç›´æ¥å½’å±äºä¸€çº§æ¨¡å—æœ¬èº«ï¼Œ
        è¿™äº›é€šå¸¸æ˜¯å…¥å£æ–‡ä»¶æˆ–å…¨å±€é…ç½®æ–‡ä»¶ã€‚

        Args:
            parent_module: çˆ¶æ¨¡å—ä¿¡æ¯ï¼ˆä¼šè¢«åŸåœ°ä¿®æ”¹ï¼Œæ›´æ–° all_filesï¼‰
            auto_assigned_sub_modules: è‡ªåŠ¨åˆ†é…åçš„å­æ¨¡å—åˆ—è¡¨

        Returns:
            è‡ªåŠ¨åˆ†é…çš„å­æ¨¡å—åˆ—è¡¨ï¼ˆä¸åšä¿®æ”¹ï¼‰
        """
        print(f"        â†’ 3.3: å¤„ç†æœªåˆ†é…æ–‡ä»¶...")

        # è®¡ç®—é—æ¼æ–‡ä»¶
        assigned_files = set()
        for sub in auto_assigned_sub_modules:
            assigned_files.update(sub.get('all_files', []))
        parent_files = set(parent_module['all_files'])
        missing_files = parent_files - assigned_files

        # æ›´æ–°çˆ¶æ¨¡å—çš„ all_files
        # éœ€è¦åŒæ—¶æ›´æ–° large_module å’Œ module_refï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if not missing_files:
            missing_files_list = []
            parent_module['all_files'] = []
            # å¦‚æœå­˜åœ¨ module_refï¼ŒåŒæ­¥æ›´æ–°åŸå§‹æ¨¡å—çš„ all_files
            if 'module_ref' in parent_module:
                parent_module['module_ref']['all_files'] = []
            print(f"           âœ“ æ‰€æœ‰æ–‡ä»¶å·²åˆ†é…åˆ°å­æ¨¡å—")
        else:
            # æŒ‰æ–‡ä»¶è·¯å¾„æ’åºï¼Œä¿è¯ç»“æœä¸€è‡´æ€§
            missing_files_list = sorted(list(missing_files))
            parent_module['all_files'] = missing_files_list
            # å¦‚æœå­˜åœ¨ module_refï¼ŒåŒæ­¥æ›´æ–°åŸå§‹æ¨¡å—çš„ all_files
            if 'module_ref' in parent_module:
                parent_module['module_ref']['all_files'] = missing_files_list
            print(f"           âœ“ {len(missing_files)} ä¸ªæ–‡ä»¶ä¿ç•™åœ¨çˆ¶æ¨¡å—ï¼ˆå…¥å£æ–‡ä»¶ç­‰ï¼‰")

        # ç›´æ¥è¿”å›è‡ªåŠ¨åˆ†é…çš„å­æ¨¡å—åˆ—è¡¨
        return auto_assigned_sub_modules

    def _extract_module_base_path(self, module_info: Dict[str, Any]) -> str:
        """
        æå–æ¨¡å—çš„åŸºç¡€è·¯å¾„

        Args:
            module_info: æ¨¡å—ä¿¡æ¯

        Returns:
            æ¨¡å—åŸºç¡€è·¯å¾„ï¼ˆå¦‚ "app_cf/lib/cf_game/"ï¼‰
        """
        # ä» all_files ä¸­æå–å…¬å…±å‰ç¼€
        all_files = module_info.get('all_files', [])
        if not all_files:
            return ''

        # æ‰¾å‡ºæ‰€æœ‰æ–‡ä»¶çš„å…¬å…±è·¯å¾„å‰ç¼€
        import os
        common_prefix = os.path.commonprefix(all_files)

        # ç¡®ä¿ä»¥ç›®å½•åˆ†éš”ç¬¦ç»“å°¾
        if common_prefix and not common_prefix.endswith('/'):
            # æ‰¾åˆ°æœ€åä¸€ä¸ª '/' ä¹‹å‰çš„éƒ¨åˆ†
            common_prefix = common_prefix.rsplit('/', 1)[0] + '/'

        return common_prefix

    def _get_repo_path(self) -> str:
        """
        è·å–ä»“åº“è·¯å¾„ï¼ˆä»æŸä¸ªåœ°æ–¹è·å–ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰

        Returns:
            ä»“åº“è·¯å¾„
        """
        # TODO: ä»é…ç½®æˆ–ä¸Šä¸‹æ–‡è·å–
        # è¿™é‡Œæš‚æ—¶è¿”å›å ä½ç¬¦ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦ä¼ å…¥
        return "/path/to/repo"

