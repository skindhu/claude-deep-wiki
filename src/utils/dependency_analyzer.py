"""
Dependency Analyzer - ä¾èµ–åˆ†æå™¨

è´Ÿè´£åˆ†æä»£ç æ–‡ä»¶ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œç”¨äºé˜¶æ®µ3çš„æ™ºèƒ½æ¨¡å—ç»†åˆ†ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ„å»ºä¾èµ–å›¾ï¼ˆæ–‡ä»¶ -> å¯¼å…¥çš„æ–‡ä»¶åˆ—è¡¨ï¼‰
2. æ£€æµ‹å¾ªç¯ä¾èµ–ï¼ˆå¼ºè¿é€šåˆ†é‡ï¼‰
3. BFSéå†ä¾èµ–å…³ç³»
4. è§£å†³å¾ªç¯ä¾èµ–å†²çª
"""

from typing import Dict, List, Set, Any, Tuple
import os
import re
from pathlib import Path
from mcp_servers.code_analysis_server import extract_imports_and_exports


class DependencyAnalyzer:
    """ä¾èµ–åˆ†æå™¨ï¼Œç”¨äºæ„å»ºå’Œåˆ†æä»£ç ä¾èµ–å…³ç³»"""

    def __init__(self):
        """
        åˆå§‹åŒ–ä¾èµ–åˆ†æå™¨
        """
        self.dependency_cache: Dict[str, List[str]] = {}  # ç¼“å­˜ä¾èµ–å…³ç³»
        self.package_map: Dict[str, str] = {}  # Dart package åç§° -> lib ç›®å½•

    def build_dependency_graph(
        self,
        files: List[str],
        repo_path: str
    ) -> Dict[str, List[str]]:
        """
        æ„å»ºå®Œæ•´ä¾èµ–å›¾ï¼šfile -> [imported files]

        Args:
            files: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            repo_path: ä»“åº“æ ¹è·¯å¾„

        Returns:
            ä¾èµ–å›¾å­—å…¸ {file_path: [imported_file1, imported_file2, ...]}
        """
        # é¦–æ¬¡æ„å»ºæ—¶æ‰«æ Dart package æ˜ å°„
        if not self.package_map:
            self.package_map = self._scan_dart_packages(repo_path)
            if self.package_map:
                print(f"        ğŸ“¦ æ£€æµ‹åˆ° {len(self.package_map)} ä¸ª Dart åŒ…")

        graph = {}

        print(f"        ğŸ”— æ„å»ºä¾èµ–å›¾ï¼ˆå…± {len(files)} ä¸ªæ–‡ä»¶ï¼‰...")

        for i, file in enumerate(files):
            if (i + 1) % 50 == 0:
                print(f"           è¿›åº¦: {i + 1}/{len(files)}")

            imports = self._extract_imports(file, repo_path)
            graph[file] = imports

        print(f"        âœ“ ä¾èµ–å›¾æ„å»ºå®Œæˆ")
        return graph

    def _extract_imports(self, file_path: str, repo_path: str) -> List[str]:
        """
        æå–æ–‡ä»¶çš„å¯¼å…¥ä¾èµ–

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            repo_path: ä»“åº“æ ¹è·¯å¾„

        Returns:
            å¯¼å…¥çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        # æ£€æŸ¥ç¼“å­˜
        if file_path in self.dependency_cache:
            return self.dependency_cache[file_path]

        try:
            # ç›´æ¥è°ƒç”¨å‡½æ•°æå–å¯¼å…¥
            result = extract_imports_and_exports(
                file_path=file_path,
                repo_root=repo_path
            )

            if result and result.get('success'):
                imports = result.get('imports', [])

                # è§£æå¯¼å…¥è·¯å¾„ä¸ºæ–‡ä»¶è·¯å¾„
                imported_files = []
                for imp in imports:
                    source = imp.get('source', '')
                    if source:
                        # è§£æç›¸å¯¹è·¯å¾„ä¸ºç»å¯¹è·¯å¾„
                        resolved = self._resolve_import_path(
                            source, file_path, repo_path
                        )
                        if resolved:
                            imported_files.append(resolved)

                # ç¼“å­˜ç»“æœ
                self.dependency_cache[file_path] = imported_files
                return imported_files

        except Exception as e:
            print(f"           âš ï¸  æå– {file_path} çš„å¯¼å…¥å¤±è´¥: {e}")

        # å¤±è´¥æ—¶è¿”å›ç©ºåˆ—è¡¨
        self.dependency_cache[file_path] = []
        return []

    def _scan_dart_packages(self, repo_path: str) -> Dict[str, str]:
        """
        æ‰«æä»“åº“ä¸­çš„ pubspec.yaml æ–‡ä»¶ï¼Œæ„å»º Dart package åˆ° lib ç›®å½•çš„æ˜ å°„
        """
        package_map: Dict[str, str] = {}
        repo = Path(repo_path).resolve()

        if not repo.exists():
            return package_map

        try:
            pubspec_files = repo.rglob('pubspec.yaml')
        except Exception as e:
            print(f"           âš ï¸  æ‰«æ pubspec.yaml å¤±è´¥: {e}")
            return package_map

        name_pattern = re.compile(r'^\s*name:\s*([^\s#]+)', re.MULTILINE)

        for pubspec in pubspec_files:
            try:
                content = pubspec.read_text(encoding='utf-8')
            except Exception:
                continue

            match = name_pattern.search(content)
            if not match:
                continue

            package_name = match.group(1).strip()
            if not package_name:
                continue

            lib_dir = pubspec.parent / 'lib'
            target_dir = lib_dir if lib_dir.exists() else pubspec.parent
            target_resolved = target_dir.resolve()

            if target_resolved.is_relative_to(repo):
                relative_path = target_resolved.relative_to(repo)
                package_map[package_name] = str(relative_path)
            else:
                package_map[package_name] = str(target_resolved)

        return package_map

    def _resolve_import_path(
        self,
        import_source: str,
        current_file: str,
        repo_path: str
    ) -> str:
        """
        è§£æå¯¼å…¥è·¯å¾„ä¸ºå®é™…æ–‡ä»¶è·¯å¾„

        Args:
            import_source: å¯¼å…¥è¯­å¥ä¸­çš„è·¯å¾„ï¼ˆå¦‚ ./utils, ../models/userï¼‰
            current_file: å½“å‰æ–‡ä»¶è·¯å¾„
            repo_path: ä»“åº“æ ¹è·¯å¾„

        Returns:
            è§£æåçš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ— æ³•è§£æåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        # ç§»é™¤åŒ…è£…ç¬¦å·ï¼ˆå¼•å·ç­‰ï¼‰
        import_source = import_source.strip('\'"')

        # å¦‚æœæ˜¯ç›¸å¯¹å¯¼å…¥
        if import_source.startswith('.'):
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
            current_dir = os.path.dirname(current_file)

            # æ‹¼æ¥è·¯å¾„
            resolved = os.path.normpath(
                os.path.join(current_dir, import_source)
            )

            if os.path.splitext(resolved)[1]:
                return resolved

            for ext in ('.dart', '.js', '.ts', '.py', '.java', '.go'):
                candidate = resolved + ext
                if os.path.exists(candidate):
                    return candidate

            return resolved

        # å¤„ç† package: å¯¼å…¥
        if import_source.startswith('package:'):
            parts = import_source.replace('package:', '', 1).split('/', 1)
            package_name = parts[0]
            relative_path = parts[1] if len(parts) > 1 else ''

            lib_dir = self.package_map.get(package_name)
            if lib_dir and relative_path:
                resolved = os.path.normpath(os.path.join(lib_dir, relative_path))
                return resolved
            elif lib_dir:
                return lib_dir

            return ''

        # å¤„ç†æœªå¸¦å‰ç¼€çš„è·¯å¾„ï¼ˆåŒç›®å½•æˆ–å­ç›®å½•ï¼‰
        if not os.path.isabs(import_source):
            current_dir = os.path.dirname(current_file)
            resolved = os.path.normpath(os.path.join(current_dir, import_source))

            if os.path.splitext(resolved)[1]:
                return resolved

            dart_candidate = resolved + '.dart'
            if os.path.exists(dart_candidate):
                return dart_candidate

            return resolved

        return ''

    def detect_circular_dependencies(
        self,
        dependency_graph: Dict[str, List[str]]
    ) -> List[Set[str]]:
        """
        æ£€æµ‹æ‰€æœ‰å¾ªç¯ä¾èµ–ç»„ï¼ˆå¼ºè¿é€šåˆ†é‡ï¼‰

        ä½¿ç”¨ Tarjan ç®—æ³•æ£€æµ‹å¼ºè¿é€šåˆ†é‡

        Args:
            dependency_graph: ä¾èµ–å›¾

        Returns:
            å¾ªç¯ä¾èµ–ç»„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ–‡ä»¶é›†åˆ
        """
        print(f"        ğŸ” æ£€æµ‹å¾ªç¯ä¾èµ–...")

        sccs = self._tarjan_scc(dependency_graph)

        print(f"        âœ“ æ£€æµ‹åˆ° {len(sccs)} ä¸ªå¾ªç¯ä¾èµ–ç»„")
        for i, scc in enumerate(sccs[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"           ç»„ {i+1}: {len(scc)} ä¸ªæ–‡ä»¶")

        return sccs

    def _tarjan_scc(self, graph: Dict[str, List[str]]) -> List[Set[str]]:
        """
        Tarjanç®—æ³•æ£€æµ‹å¼ºè¿é€šåˆ†é‡ï¼ˆå¾ªç¯ä¾èµ–ç»„ï¼‰

        Args:
            graph: ä¾èµ–å›¾ {file: [imported_files]}

        Returns:
            å¼ºè¿é€šåˆ†é‡åˆ—è¡¨ï¼ˆæ¯ä¸ªå¤§å°>1è¡¨ç¤ºæœ‰å¾ªç¯ï¼‰
        """
        index_counter = [0]
        stack = []
        lowlinks = {}
        index = {}
        on_stack = {}
        sccs = []

        def strongconnect(node):
            # è®¾ç½®èŠ‚ç‚¹çš„ç´¢å¼•
            index[node] = index_counter[0]
            lowlinks[node] = index_counter[0]
            index_counter[0] += 1
            on_stack[node] = True
            stack.append(node)

            # éå†åç»§èŠ‚ç‚¹
            for successor in graph.get(node, []):
                if successor not in index:
                    # åç»§èŠ‚ç‚¹æœªè®¿é—®ï¼Œé€’å½’
                    strongconnect(successor)
                    lowlinks[node] = min(lowlinks[node], lowlinks[successor])
                elif on_stack.get(successor, False):
                    # åç»§èŠ‚ç‚¹åœ¨æ ˆä¸­ï¼Œè¯´æ˜æ‰¾åˆ°ç¯
                    lowlinks[node] = min(lowlinks[node], index[successor])

            # å¦‚æœæ˜¯å¼ºè¿é€šåˆ†é‡çš„æ ¹
            if lowlinks[node] == index[node]:
                scc = set()
                while True:
                    w = stack.pop()
                    on_stack[w] = False
                    scc.add(w)
                    if w == node:
                        break

                # åªè¿”å›çœŸæ­£çš„å¾ªç¯ï¼ˆå¤§å°>1ï¼‰
                if len(scc) > 1:
                    sccs.append(scc)

        # å¯¹æ‰€æœ‰æœªè®¿é—®çš„èŠ‚ç‚¹æ‰§è¡Œç®—æ³•
        for node in graph:
            if node not in index:
                strongconnect(node)

        return sccs

    async def traverse_dependencies(
        self,
        start_files: List[str],
        dependency_graph: Dict[str, List[str]],
        max_depth: int = 5,
        scope_pattern: str = None
    ) -> Set[str]:
        """
        BFSéå†ä¾èµ–ï¼Œä½¿ç”¨visitedé›†åˆé˜²æ­¢å¾ªç¯

        Args:
            start_files: èµ·å§‹æ–‡ä»¶ï¼ˆå…¥å£+å…³é”®æ–‡ä»¶ï¼‰
            dependency_graph: ä¾èµ–å›¾
            max_depth: æœ€å¤§éå†æ·±åº¦ï¼ˆé˜²æ­¢è¿‡åº¦åŒ…å«ï¼‰
            scope_pattern: é™å®šèŒƒå›´ï¼ˆå¦‚ "app_cf/lib/cf_game/"ï¼‰ï¼ŒåªåŒ…å«æ­¤å‰ç¼€çš„æ–‡ä»¶

        Returns:
            æ‰€æœ‰ç›¸å…³æ–‡ä»¶çš„é›†åˆ
        """
        visited = set()
        queue = [(f, 0) for f in start_files]  # (file, depth)
        result = set(start_files)

        while queue:
            current_file, depth = queue.pop(0)

            # è¶…è¿‡æ·±åº¦é™åˆ¶æˆ–å·²è®¿é—®ï¼Œè·³è¿‡
            if depth >= max_depth or current_file in visited:
                continue

            visited.add(current_file)

            # è·å–å½“å‰æ–‡ä»¶çš„å¯¼å…¥
            imports = dependency_graph.get(current_file, [])

            for imported_file in imports:
                # èŒƒå›´è¿‡æ»¤ï¼šåªä¿ç•™èŒƒå›´å†…çš„æ–‡ä»¶
                if scope_pattern and not imported_file.startswith(scope_pattern):
                    continue

                # æ·»åŠ åˆ°ç»“æœé›†
                if imported_file not in result:
                    result.add(imported_file)
                    queue.append((imported_file, depth + 1))

        return result

    def topological_sort_files(
        self,
        files: List[str],
        dependency_graph: Dict[str, List[str]]
    ) -> List[str]:
        """
        å¯¹æ–‡ä»¶åˆ—è¡¨è¿›è¡Œæ‹“æ‰‘æ’åºï¼Œä½¿ä¾èµ–åœ¨å‰ï¼Œè¢«ä¾èµ–è€…åœ¨å

        Args:
            files: éœ€è¦æ’åºçš„æ–‡ä»¶åˆ—è¡¨
            dependency_graph: ä¾èµ–å›¾ {file: [imported_files]}

        Returns:
            æŒ‰ä¾èµ–é¡ºåºæ’åˆ—çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆè¢«ä¾èµ–çš„æ–‡ä»¶åœ¨å‰ï¼‰
        """
        # åªå¤„ç†åœ¨filesåˆ—è¡¨ä¸­çš„æ–‡ä»¶
        file_set = set(files)

        # æ„å»ºåå‘ä¾èµ–å›¾ï¼ˆè®¡ç®—å…¥åº¦ï¼‰
        in_degree: Dict[str, int] = {f: 0 for f in files}
        reverse_graph: Dict[str, List[str]] = {f: [] for f in files}

        for file in files:
            # åªè€ƒè™‘åœ¨filesåˆ—è¡¨ä¸­çš„ä¾èµ–
            dependencies = [
                dep for dep in dependency_graph.get(file, [])
                if dep in file_set
            ]
            for dep in dependencies:
                in_degree[file] = in_degree.get(file, 0) + 1
                if dep not in reverse_graph:
                    reverse_graph[dep] = []
                reverse_graph[dep].append(file)

        # Kahnç®—æ³•ï¼šæ‰¾åˆ°æ‰€æœ‰å…¥åº¦ä¸º0çš„èŠ‚ç‚¹
        queue = [f for f in files if in_degree.get(f, 0) == 0]
        result = []
        processed = set()

        # å¤„ç†å¾ªç¯ä¾èµ–ï¼šå¦‚æœæ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰å…¥åº¦ï¼Œè¯´æ˜å­˜åœ¨å¾ªç¯
        # åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒæŒ‰å­—æ¯é¡ºåºå¤„ç†
        if not queue:
            # æ‰€æœ‰æ–‡ä»¶éƒ½åœ¨å¾ªç¯ä¸­ï¼ŒæŒ‰å­—æ¯é¡ºåºè¿”å›
            return sorted(files)

        # æ‹“æ‰‘æ’åºä¸»å¾ªç¯
        while queue:
            # æŒ‰å­—æ¯é¡ºåºå¤„ç†ï¼Œä¿è¯ç»“æœç¨³å®š
            queue.sort()
            current = queue.pop(0)

            if current in processed:
                continue

            result.append(current)
            processed.add(current)

            # æ›´æ–°ä¾èµ–å½“å‰èŠ‚ç‚¹çš„æ–‡ä»¶çš„å…¥åº¦
            for dependent in reverse_graph.get(current, []):
                if dependent in processed:
                    continue
                in_degree[dependent] = in_degree.get(dependent, 0) - 1
                if in_degree[dependent] == 0:
                    queue.append(dependent)

        # å¤„ç†å‰©ä½™çš„å¾ªç¯ä¾èµ–èŠ‚ç‚¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        remaining = [f for f in files if f not in processed]
        if remaining:
            # å¯¹å¾ªç¯ä¾èµ–çš„æ–‡ä»¶æŒ‰å­—æ¯é¡ºåºæ·»åŠ åˆ°æœ«å°¾
            result.extend(sorted(remaining))

        return result

    def filter_by_scope(
        self,
        files: Set[str],
        module_base_path: str
    ) -> Set[str]:
        """
        è¿‡æ»¤æ–‡ä»¶ï¼Œç¡®ä¿å®ƒä»¬åœ¨æ¨¡å—çš„èŒƒå›´å†…

        Args:
            files: æ–‡ä»¶é›†åˆ
            module_base_path: æ¨¡å—åŸºç¡€è·¯å¾„ï¼ˆå¦‚ "app_cf/lib/cf_game/"ï¼‰

        Returns:
            è¿‡æ»¤åçš„æ–‡ä»¶é›†åˆ
        """
        return {f for f in files if f.startswith(module_base_path)}

    def match_config_files_by_path(
        self,
        sub_module_name: str,
        orphan_files: List[str],
        module_base_path: str
    ) -> List[str]:
        """
        æ ¹æ®è·¯å¾„å…³é”®è¯åŒ¹é…é…ç½®å’Œèµ„æºæ–‡ä»¶åˆ°å­æ¨¡å—

        Args:
            sub_module_name: å­æ¨¡å—åç§°
            orphan_files: æœªåˆ†é…çš„æ–‡ä»¶åˆ—è¡¨
            module_base_path: æ¨¡å—åŸºç¡€è·¯å¾„

        Returns:
            åŒ¹é…åˆ°çš„é…ç½®æ–‡ä»¶åˆ—è¡¨
        """
        # ä»å­æ¨¡å—åç§°æå–å…³é”®è¯ï¼ˆå¦‚ "åœ°å›¾æ¨èåŠŸèƒ½" -> "map", "recommend"ï¼‰
        keywords = self._extract_keywords_from_name(sub_module_name)

        matched = []
        for file in orphan_files:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æ¨¡å—èŒƒå›´å†…
            if not file.startswith(module_base_path):
                continue

            # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ…å«å…³é”®è¯
            file_lower = file.lower()
            for keyword in keywords:
                if keyword in file_lower:
                    matched.append(file)
                    break

        return matched

    def _extract_keywords_from_name(self, name: str) -> List[str]:
        """
        ä»æ¨¡å—åç§°æå–å…³é”®è¯

        Args:
            name: æ¨¡å—åç§°ï¼ˆå¦‚ "ç”¨æˆ·ç®¡ç†åŠŸèƒ½"ï¼‰

        Returns:
            å…³é”®è¯åˆ—è¡¨ï¼ˆå¦‚ ["user", "management"]ï¼‰
        """
        # ä¸­æ–‡è½¬æ‹¼éŸ³å…³é”®è¯æ˜ å°„ï¼ˆç®€åŒ–ç‰ˆï¼‰
        chinese_to_english = {
            'ç”¨æˆ·': 'user',
            'è®¢å•': 'order',
            'å•†å“': 'product',
            'æ”¯ä»˜': 'payment',
            'è´­ç‰©è½¦': 'cart',
            'åœ°å€': 'address',
            'è¯„ä»·': 'review',
            'æ”¶è—': 'favorite',
            'æœç´¢': 'search',
            'æ¨è': 'recommend',
            'ç»Ÿè®¡': 'statistics',
            'æ•°æ®': 'data',
        }

        keywords = []

        # æå–ä¸­æ–‡å…³é”®è¯
        for chinese, english in chinese_to_english.items():
            if chinese in name:
                keywords.append(english)

        # æå–è‹±æ–‡å…³é”®è¯ï¼ˆä½¿ç”¨ä¸‹åˆ’çº¿æˆ–é©¼å³°åˆ†å‰²ï¼‰
        # ä¾‹å¦‚ï¼š"map_recommend" -> ["map", "recommend"]
        words = re.findall(r'[a-z]+', name.lower())
        keywords.extend(words)

        return list(set(keywords))  # å»é‡


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# å¾ªç¯ä¾èµ–è§£å†³ç­–ç•¥
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def resolve_circular_conflicts(
    sub_modules: List[Dict[str, Any]],
    circular_groups: List[Set[str]],
    dependency_graph: Dict[str, List[str]]
) -> None:
    """
    è§£å†³å¾ªç¯ä¾èµ–å¯¼è‡´çš„æ–‡ä»¶å½’å±å†²çª

    æ ¸å¿ƒæ€æƒ³ï¼š
    1. è®¡ç®—æ¯ä¸ªå­æ¨¡å—å¯¹å¾ªç¯ç»„çš„"ç´§å¯†åº¦å¾—åˆ†"
    2. å°†æ•´ä¸ªå¾ªç¯ç»„å½’å±åˆ°å¾—åˆ†æœ€é«˜çš„å­æ¨¡å—
    3. å…¶ä»–å­æ¨¡å—æ ‡è®°ä¸º shared_dependencies

    Args:
        sub_modules: å­æ¨¡å—åˆ—è¡¨ï¼ˆä¼šè¢«åŸåœ°ä¿®æ”¹ï¼‰
        circular_groups: å¾ªç¯ä¾èµ–ç»„åˆ—è¡¨
        dependency_graph: ä¾èµ–å›¾
    """
    print(f"        ğŸ”§ è§£å†³å¾ªç¯ä¾èµ–å†²çª...")

    for circular_group in circular_groups:
        involved_modules = []

        # æ‰¾å‡ºæ¶‰åŠè¯¥å¾ªç¯ç»„çš„æ‰€æœ‰å­æ¨¡å—
        for sub_module in sub_modules:
            preliminary_files = set(sub_module.get('preliminary_files', []))
            overlap = circular_group & preliminary_files

            if not overlap:
                continue  # è¯¥å­æ¨¡å—ä¸æ¶‰åŠæ­¤å¾ªç¯ç»„

            # è®¡ç®—ç´§å¯†åº¦å¾—åˆ†ï¼ˆå¤šå› ç´ ï¼‰
            score = calculate_cohesion_score(
                sub_module=sub_module,
                circular_group=circular_group,
                overlap=overlap,
                dependency_graph=dependency_graph
            )

            involved_modules.append({
                'module': sub_module,
                'score': score,
                'overlap': overlap
            })

        # å¦‚æœåªæœ‰ä¸€ä¸ªæˆ–é›¶ä¸ªæ¨¡å—æ¶‰åŠï¼Œæ— å†²çª
        if len(involved_modules) <= 1:
            continue

        # æŒ‰å¾—åˆ†æ’åºï¼Œæœ€é«˜åˆ†çš„æ¨¡å—è·å¾—å½’å±æƒ
        involved_modules.sort(key=lambda x: x['score'], reverse=True)
        winner = involved_modules[0]

        print(f"           å¾ªç¯ç»„ ({len(circular_group)} ä¸ªæ–‡ä»¶) -> {winner['module']['name']}")

        # ä»å…¶ä»–æ¨¡å—ç§»é™¤è¯¥å¾ªç¯ç»„
        for item in involved_modules[1:]:
            module = item['module']
            module['preliminary_files'] = [
                f for f in module['preliminary_files']
                if f not in circular_group
            ]

            # æ ‡è®°ä¸ºå…±äº«ä¾èµ–
            if 'shared_dependencies' not in module:
                module['shared_dependencies'] = []
            module['shared_dependencies'].extend(list(item['overlap']))


def calculate_cohesion_score(
    sub_module: Dict[str, Any],
    circular_group: Set[str],
    overlap: Set[str],
    dependency_graph: Dict[str, List[str]]
) -> float:
    """
    è®¡ç®—å­æ¨¡å—å¯¹å¾ªç¯ç»„çš„ç´§å¯†åº¦å¾—åˆ†

    è¯„åˆ†å› ç´ ï¼š
    1. å…¥å£æ–‡ä»¶æ•°é‡ï¼ˆæƒé‡3ï¼‰ï¼šå¾ªç¯ç»„ä¸­æœ‰å¤šå°‘ä¸ªæ˜¯å…¥å£æ–‡ä»¶
    2. å…³é”®æ–‡ä»¶æ•°é‡ï¼ˆæƒé‡2ï¼‰ï¼šå¾ªç¯ç»„ä¸­æœ‰å¤šå°‘ä¸ªæ˜¯å…³é”®æ–‡ä»¶
    3. è·¯å¾„è·ç¦»ï¼ˆæƒé‡1ï¼‰ï¼šå¾ªç¯ç»„æ–‡ä»¶ä¸å­æ¨¡å—è·¯å¾„çš„å¹³å‡è·ç¦»
    4. ä¾èµ–å¯†åº¦ï¼ˆæƒé‡1ï¼‰ï¼šå¾ªç¯ç»„å†…éƒ¨ä¾èµ–vså¤–éƒ¨ä¾èµ–çš„æ¯”ä¾‹

    Args:
        sub_module: å­æ¨¡å—ä¿¡æ¯
        circular_group: å¾ªç¯ä¾èµ–ç»„
        overlap: å­æ¨¡å—ä¸å¾ªç¯ç»„çš„äº¤é›†
        dependency_graph: ä¾èµ–å›¾

    Returns:
        ç´§å¯†åº¦å¾—åˆ†ï¼ˆå½’ä¸€åŒ–ï¼‰
    """
    score = 0.0

    # å› ç´ 1ï¼šå…¥å£æ–‡ä»¶ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    entry_files = set(sub_module.get('suggested_entry_files', []))
    entry_count = len(overlap & entry_files)
    score += entry_count * 3.0

    # å› ç´ 2ï¼šå…³é”®æ–‡ä»¶
    key_files = set(sub_module.get('suggested_key_files', []))
    key_count = len(overlap & key_files)
    score += key_count * 2.0

    # å› ç´ 3ï¼šè·¯å¾„è·ç¦»ï¼ˆè¶Šè¿‘è¶Šå¥½ï¼‰
    module_name = sub_module.get('name', '')
    path_distances = []

    for file in overlap:
        distance = calculate_path_distance(file, module_name)
        path_distances.append(distance)

    if path_distances:
        avg_distance = sum(path_distances) / len(path_distances)
        # è·ç¦»è¶Šè¿‘åˆ†æ•°è¶Šé«˜ï¼ˆ10 - distanceï¼‰
        score += max(0, 10 - min(avg_distance, 10)) * 1.0

    # å› ç´ 4ï¼šä¾èµ–å¯†åº¦
    internal_deps = count_internal_dependencies(
        circular_group, overlap, dependency_graph
    )
    external_deps = count_external_dependencies(
        circular_group, overlap, dependency_graph
    )

    if internal_deps + external_deps > 0:
        density = internal_deps / (internal_deps + external_deps)
        score += density * 1.0

    # å½’ä¸€åŒ–ï¼ˆé˜²æ­¢å¾ªç¯ç»„å¤§å°å½±å“ï¼‰
    normalized_score = score / len(circular_group) if len(circular_group) > 0 else 0

    return normalized_score


def calculate_path_distance(file_path: str, module_name: str) -> int:
    """
    è®¡ç®—æ–‡ä»¶è·¯å¾„ä¸æ¨¡å—åç§°çš„"è·ç¦»"

    ç®€åŒ–ç­–ç•¥ï¼šç»Ÿè®¡æ–‡ä»¶è·¯å¾„ä¸­ä¸åŒ…å«æ¨¡å—åç§°å…³é”®è¯çš„å±‚çº§æ•°

    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        module_name: æ¨¡å—åç§°

    Returns:
        è·ç¦»å€¼ï¼ˆ0è¡¨ç¤ºå®Œå…¨åŒ¹é…ï¼‰
    """
    # æå–æ¨¡å—åç§°ä¸­çš„å…³é”®è¯ï¼ˆè½¬å°å†™ï¼‰
    module_keywords = re.findall(r'[a-z]+', module_name.lower())

    # æ–‡ä»¶è·¯å¾„è½¬å°å†™
    file_lower = file_path.lower()

    # å¦‚æœæ–‡ä»¶è·¯å¾„åŒ…å«ä»»æ„å…³é”®è¯ï¼Œè·ç¦»ä¸º0
    for keyword in module_keywords:
        if keyword in file_lower:
            return 0

    # å¦åˆ™ï¼Œè·ç¦»ä¸ºè·¯å¾„å±‚çº§æ•°
    return file_path.count('/')


def count_internal_dependencies(
    circular_group: Set[str],
    overlap: Set[str],
    dependency_graph: Dict[str, List[str]]
) -> int:
    """
    ç»Ÿè®¡å¾ªç¯ç»„å†…éƒ¨çš„ä¾èµ–æ•°é‡

    Args:
        circular_group: å¾ªç¯ä¾èµ–ç»„
        overlap: å­æ¨¡å—ä¸å¾ªç¯ç»„çš„äº¤é›†
        dependency_graph: ä¾èµ–å›¾

    Returns:
        å†…éƒ¨ä¾èµ–æ•°é‡
    """
    count = 0
    for file in overlap:
        imports = dependency_graph.get(file, [])
        for imp in imports:
            if imp in circular_group:
                count += 1
    return count


def count_external_dependencies(
    circular_group: Set[str],
    overlap: Set[str],
    dependency_graph: Dict[str, List[str]]
) -> int:
    """
    ç»Ÿè®¡å¾ªç¯ç»„å¤–éƒ¨çš„ä¾èµ–æ•°é‡

    Args:
        circular_group: å¾ªç¯ä¾èµ–ç»„
        overlap: å­æ¨¡å—ä¸å¾ªç¯ç»„çš„äº¤é›†
        dependency_graph: ä¾èµ–å›¾

    Returns:
        å¤–éƒ¨ä¾èµ–æ•°é‡
    """
    count = 0
    for file in overlap:
        imports = dependency_graph.get(file, [])
        for imp in imports:
            if imp not in circular_group:
                count += 1
    return count

